package main

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"strings"
	"sync"
	"sync/atomic"
	"time"
)

// runPortChecks è´Ÿè´£ç‹¬ç«‹æ‰§è¡Œç«¯å£ç›‘æ§
func runPortChecks(config Config, statuses map[string]*ServerStatus) {
	if !config.Monitor.PortMonitor {
		return
	}
	if !portRunning.CompareAndSwap(false, true) {
		//log.Println("[ monitorPorts ] already running, skip this round")
		return
	}
	startTime := time.Now()

	log.Println("[ monitorPorts ] function starts")
	defer func() {
		duration := time.Since(startTime)
		log.Printf("[ monitorPorts ] function completed (duration: %.4fs)", duration.Seconds())
		portRunning.Store(false)
	}()

	var wg sync.WaitGroup
	jobChan := make(chan serverJob, maxWorkers)

	// å¯åŠ¨ worker
	for i := 0; i < maxWorkers; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for job := range jobChan {
				if job.server.PortCheck != nil && !*job.server.PortCheck {
					continue
				}
				// åªæ‰§è¡Œç«¯å£æ£€æŸ¥ç›¸å…³é€»è¾‘
				pingState := checkPingState(job.address)
				if !pingState {
					continue // æœåŠ¡å™¨ä¸é€šï¼Œè·³è¿‡
				}
				portState := checkPort(job.address, job.port)

				// è·å–çŠ¶æ€å¯¹è±¡
				statusesMutex.Lock()
				status, ok := statuses[job.key]
				if !ok { // å¦‚æœ map ä¸­ä¸å­˜åœ¨è¿™ä¸ª key
					// åˆ›å»ºæ–°çš„ status å¯¹è±¡
					status = &ServerStatus{
						PortStates: make(map[string]*StateTracker), // [æ–°å¢]
						//ProcessAlertSent:    make(map[string]int32),
						ProcessStates: make(map[string]*StateTracker),
						CpuAlertSent:  0,
						MemAlertSent:  0,
						DiskAlertSent: make(map[string]int32),
						DirAlertSent:  make(map[string]int32),
						FileAlertSent: make(map[string]int32),
						//PingAlertSent:       0,
						PingState:        &StateTracker{},
						TargetPortStates: make(map[string]*StateTracker),
					}
					// å°†æ–°åˆ›å»ºçš„å¯¹è±¡å­˜å…¥ map
					statuses[job.key] = status
				}
				statusesMutex.Unlock()

				handlePortStatus(job.address, job.port, job.key, portState, status, config)
			}
		}()
	}

	// åˆ†å‘ä»»åŠ¡
	distributePortJobs(config, jobChan)
	wg.Wait()
	//log.Println("[ monitorPorts ] function completed")
}

// runProcessChecks è´Ÿè´£ç‹¬ç«‹æ‰§è¡Œè¿›ç¨‹ç›‘æ§
func runProcessChecks(config Config, statuses map[string]*ServerStatus) {
	if !config.Monitor.ProcessMonitor {
		return
	}
	if !processRunning.CompareAndSwap(false, true) {
		//log.Println("[ monitorProcesses ] already running, skip this round")
		return
	}
	startTime := time.Now()
	log.Println("[ monitorProcesses ] function starts")
	defer func() {
		duration := time.Since(startTime)
		log.Printf("[ monitorProcesses ] function completed (duration: %.4fs)", duration.Seconds())
		processRunning.Store(false)
	}()

	var wg sync.WaitGroup
	jobChan := make(chan serverJob, maxWorkers)

	// å¯åŠ¨ worker
	for i := 0; i < maxWorkers; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for job := range jobChan {
				if job.server.ProcessCheck != nil && !*job.server.ProcessCheck {
					continue
				}
				// åªæ‰§è¡Œè¿›ç¨‹æ£€æŸ¥ç›¸å…³é€»è¾‘
				pingState := checkPingState(job.address)
				if !pingState {
					continue // æœåŠ¡å™¨ä¸é€šï¼Œè·³è¿‡
				}
				statusResponse, err := getCachedCheckData(job.address)
				if err != nil {
					//log.Printf("Error getting check data for %s: %v", job.address, err)
					continue
				}

				// è·å–çŠ¶æ€å¯¹è±¡
				statusesMutex.Lock()
				status, ok := statuses[job.key]
				if !ok { // å¦‚æœ map ä¸­ä¸å­˜åœ¨è¿™ä¸ª key
					// åˆ›å»ºæ–°çš„ status å¯¹è±¡
					status = &ServerStatus{
						PortStates: make(map[string]*StateTracker), // [æ–°å¢]
						//ProcessAlertSent:    make(map[string]int32),
						ProcessStates: make(map[string]*StateTracker),
						CpuAlertSent:  0,
						MemAlertSent:  0,
						DiskAlertSent: make(map[string]int32),
						DirAlertSent:  make(map[string]int32),
						FileAlertSent: make(map[string]int32),
						//PingAlertSent:       0,
						PingState:        &StateTracker{},
						TargetPortStates: make(map[string]*StateTracker),
					}
					// å°†æ–°åˆ›å»ºçš„å¯¹è±¡å­˜å…¥ map
					statuses[job.key] = status
				}
				statusesMutex.Unlock()

				handleProcessStatus(job.address, job.key, statusResponse.ProcessStatuses, status, config)
			}
		}()
	}

	// åˆ†å‘ä»»åŠ¡
	distributeAddressJobs(config, jobChan)
	wg.Wait()
	//log.Println("[ monitorProcesses ] function completed")
}

// runPingChecks è´Ÿè´£ç‹¬ç«‹æ‰§è¡ŒæœåŠ¡å™¨é€šä¿¡çŠ¶æ€ç›‘æ§
func runPingChecks(config Config, statuses map[string]*ServerStatus) {
	if !config.Monitor.ServerReachMonitor {
		return
	}
	if !pingRunning.CompareAndSwap(false, true) {
		//log.Println("[ monitorPorts ] already running, skip this round")
		return
	}
	startTime := time.Now()

	log.Println("[ monitorPing ] function starts")
	defer func() {
		duration := time.Since(startTime)
		log.Printf("[ monitorPing ] function completed (duration: %.4fs)", duration.Seconds())
		pingRunning.Store(false)
	}()

	var wg sync.WaitGroup
	jobChan := make(chan serverJob, maxWorkers)

	// å¯åŠ¨ worker
	for i := 0; i < maxWorkers; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for job := range jobChan {
				// *** æ–°å¢åˆ¤æ–­ ***
				if job.server.PingCheck != nil && !*job.server.PingCheck {
					continue
				}
				pingState := checkPingState(job.address)

				// è·å–çŠ¶æ€å¯¹è±¡
				statusesMutex.Lock()
				status, ok := statuses[job.key]
				if !ok { // å¦‚æœ map ä¸­ä¸å­˜åœ¨è¿™ä¸ª key
					// åˆ›å»ºæ–°çš„ status å¯¹è±¡
					status = &ServerStatus{
						PortStates: make(map[string]*StateTracker), // [æ–°å¢]
						//ProcessAlertSent:    make(map[string]int32),
						ProcessStates: make(map[string]*StateTracker),
						CpuAlertSent:  0,
						MemAlertSent:  0,
						DiskAlertSent: make(map[string]int32),
						DirAlertSent:  make(map[string]int32),
						FileAlertSent: make(map[string]int32),
						//PingAlertSent:       0,
						PingState:        &StateTracker{},
						TargetPortStates: make(map[string]*StateTracker),
					}
					// å°†æ–°åˆ›å»ºçš„å¯¹è±¡å­˜å…¥ map
					statuses[job.key] = status
				}
				statusesMutex.Unlock()

				handlePingStatus(job.address, job.key, pingState, status, config)
			}
		}()
	}

	// åˆ†å‘ä»»åŠ¡
	distributeAddressJobs(config, jobChan)
	wg.Wait()
	//log.Println("[ monitorPing ] function completed")
}

// runResourceChecks è´Ÿè´£ç‹¬ç«‹æ‰§è¡ŒæœåŠ¡å™¨èµ„æºçŠ¶æ€ç›‘æ§
func runResourceChecks(config Config, statuses map[string]*ServerStatus) {
	if !config.Monitor.Resource {
		return
	}
	if !resourceRunning.CompareAndSwap(false, true) {
		//log.Println("[ monitorPorts ] already running, skip this round")
		return
	}
	startTime := time.Now()

	log.Println("[ monitorResource ] function starts")
	defer func() {
		duration := time.Since(startTime)
		log.Printf("[ monitorResource ] function completed (duration: %.4fs)", duration.Seconds())
		resourceRunning.Store(false)
	}()

	var wg sync.WaitGroup
	jobChan := make(chan serverJob, maxWorkers)

	// å¯åŠ¨ worker
	for i := 0; i < maxWorkers; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for job := range jobChan {
				if job.server.ResourceCheck != nil && !*job.server.ResourceCheck {
					continue
				}
				pingState := checkPingState(job.address)
				if !pingState {
					continue // æœåŠ¡å™¨ä¸é€šï¼Œè·³è¿‡
				}
				statusResponse, err := getCachedCheckData(job.address)
				if err != nil {
					//log.Printf("Error getting check data for %s: %v", job.address, err)
					continue
				}

				// è·å–çŠ¶æ€å¯¹è±¡
				statusesMutex.Lock()
				status, ok := statuses[job.key]
				if !ok { // å¦‚æœ map ä¸­ä¸å­˜åœ¨è¿™ä¸ª key
					// åˆ›å»ºæ–°çš„ status å¯¹è±¡
					status = &ServerStatus{
						PortStates: make(map[string]*StateTracker), // [æ–°å¢]
						//ProcessAlertSent:    make(map[string]int32),
						ProcessStates: make(map[string]*StateTracker),
						CpuAlertSent:  0,
						MemAlertSent:  0,
						DiskAlertSent: make(map[string]int32),
						DirAlertSent:  make(map[string]int32),
						FileAlertSent: make(map[string]int32),
						//PingAlertSent:       0,
						PingState:        &StateTracker{},
						TargetPortStates: make(map[string]*StateTracker),
					}
					// å°†æ–°åˆ›å»ºçš„å¯¹è±¡å­˜å…¥ map
					statuses[job.key] = status
				}
				statusesMutex.Unlock()

				handleResourceStatus(job.address, job.key, statusResponse.Metrics, job.server, status, config)
			}
		}()
	}

	// åˆ†å‘ä»»åŠ¡
	distributeAddressJobs(config, jobChan)
	wg.Wait()
	//log.Println("[ monitorResource ] function completed")
}

// runDirectoryChecks è´Ÿè´£ç‹¬ç«‹æ‰§è¡ŒæœåŠ¡å™¨èµ„æºçŠ¶æ€ç›‘æ§
func runDirectoryChecks(config Config, statuses map[string]*ServerStatus) {
	if !config.Monitor.DirFileMonitor {
		return
	}
	if !directoryRunning.CompareAndSwap(false, true) {
		//log.Println("[ monitorPorts ] already running, skip this round")
		return
	}
	startTime := time.Now()

	log.Println("[ monitorDirectory ] function starts")
	defer func() {
		duration := time.Since(startTime)
		log.Printf("[ monitorDirectory ] function completed (duration: %.4fs)", duration.Seconds())
		directoryRunning.Store(false)
	}()

	var wg sync.WaitGroup
	jobChan := make(chan serverJob, maxWorkers)
	now := time.Now()

	// å¯åŠ¨ worker
	for i := 0; i < maxWorkers; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for job := range jobChan {
				if job.server.DirectoryCheck != nil && !*job.server.DirectoryCheck {
					continue
				}
				pingState := checkPingState(job.address)
				if !pingState {
					continue // æœåŠ¡å™¨ä¸é€šï¼Œè·³è¿‡
				}
				statusResponse, err := getCachedCheckData(job.address)
				if err != nil {
					//log.Printf("Error getting check data for %s: %v", job.address, err)
					continue
				}

				// è·å–çŠ¶æ€å¯¹è±¡
				statusesMutex.Lock()
				status, ok := statuses[job.key]
				if !ok { // å¦‚æœ map ä¸­ä¸å­˜åœ¨è¿™ä¸ª key
					// åˆ›å»ºæ–°çš„ status å¯¹è±¡
					status = &ServerStatus{
						PortStates: make(map[string]*StateTracker), // [æ–°å¢]
						//ProcessAlertSent:    make(map[string]int32),
						ProcessStates: make(map[string]*StateTracker),
						CpuAlertSent:  0,
						MemAlertSent:  0,
						DiskAlertSent: make(map[string]int32),
						DirAlertSent:  make(map[string]int32),
						FileAlertSent: make(map[string]int32),
						//PingAlertSent:       0,
						PingState:        &StateTracker{},
						TargetPortStates: make(map[string]*StateTracker),
					}
					// å°†æ–°åˆ›å»ºçš„å¯¹è±¡å­˜å…¥ map
					statuses[job.key] = status
				}
				statusesMutex.Unlock()

				handleDirectoryStatus(job.address, job.key, statusResponse.DirectoryStatuses, status, config, now)
			}
		}()
	}

	// åˆ†å‘ä»»åŠ¡
	distributeAddressJobs(config, jobChan)
	wg.Wait()
	//log.Println("[ monitorDirectory ] function completed")
}

// runTargetPortChecks è´Ÿè´£ç‹¬ç«‹æ‰§è¡ŒæœåŠ¡å™¨èµ„æºçŠ¶æ€ç›‘æ§
func runTargetPortChecks(config Config, statuses map[string]*ServerStatus) {
	if !config.Monitor.RaPortMonitor {
		return
	}
	if !targetPortRunning.CompareAndSwap(false, true) {
		//log.Println("[ monitorPorts ] already running, skip this round")
		return
	}
	startTime := time.Now()

	log.Println("[ monitorTargetPort ] function starts")
	defer func() {
		duration := time.Since(startTime)
		log.Printf("[ monitorTargetPort ] function completed (duration: %.4fs)", duration.Seconds())
		targetPortRunning.Store(false)
	}()

	var wg sync.WaitGroup
	jobChan := make(chan serverJob, maxWorkers)

	// å¯åŠ¨ worker
	for i := 0; i < maxWorkers; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for job := range jobChan {
				if job.server.TargetPortCheck != nil && !*job.server.TargetPortCheck {
					continue
				}
				pingState := checkPingState(job.address)
				if !pingState {
					continue // æœåŠ¡å™¨ä¸é€šï¼Œè·³è¿‡
				}
				statusResponse, err := getCachedCheckData(job.address)
				if err != nil {
					//log.Printf("Error getting check data for %s: %v", job.address, err)
					continue
				}

				// è·å–çŠ¶æ€å¯¹è±¡
				statusesMutex.Lock()
				status, ok := statuses[job.key]
				if !ok { // å¦‚æœ map ä¸­ä¸å­˜åœ¨è¿™ä¸ª key
					// åˆ›å»ºæ–°çš„ status å¯¹è±¡
					status = &ServerStatus{
						PortStates: make(map[string]*StateTracker), // [æ–°å¢]
						//ProcessAlertSent:    make(map[string]int32),
						ProcessStates: make(map[string]*StateTracker),
						CpuAlertSent:  0,
						MemAlertSent:  0,
						DiskAlertSent: make(map[string]int32),
						DirAlertSent:  make(map[string]int32),
						FileAlertSent: make(map[string]int32),
						//PingAlertSent:       0,
						PingState:        &StateTracker{},
						TargetPortStates: make(map[string]*StateTracker),
					}
					// å°†æ–°åˆ›å»ºçš„å¯¹è±¡å­˜å…¥ map
					statuses[job.key] = status
				}
				statusesMutex.Unlock()

				handleTargetPortStatus(job.address, job.key, statusResponse.PortStatuses, status, config)
			}
		}()
	}

	// åˆ†å‘ä»»åŠ¡
	distributeAddressJobs(config, jobChan)
	wg.Wait()
	//log.Println("[ monitorTargetPort ] function completed")
}

// å¯é€‰ï¼šåˆ›å»ºä¸€ä¸ªè¾…åŠ©å‡½æ•°æ¥åˆ†å‘ä»»åŠ¡ï¼Œé¿å…ä»£ç é‡å¤
func distributePortJobs(config Config, jobChan chan<- serverJob) {
	// éå†æ‰€æœ‰æœåŠ¡å™¨ã€åœ°å€å’Œç«¯å£æ¥åˆ›å»ºä»»åŠ¡
	for _, server := range config.Servers {
		for _, address := range server.Addresses {
			// å¯¹äºè¿›ç¨‹ã€èµ„æºç­‰éç«¯å£ç‰¹å®šçš„ç›‘æ§ï¼Œæˆ‘ä»¬åªéœ€è¦æ¯ä¸ªåœ°å€ä¸€ä¸ªä»»åŠ¡
			// è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ä»ç„¶ç”¨ address:port ä½œä¸º keyï¼Œä½†å¯ä»¥ä¼˜åŒ–
			if len(server.Ports) == 0 { // å¦‚æœæ²¡æœ‰ç«¯å£ï¼Œè‡³å°‘ä¸ºåœ°å€åˆ›å»ºä¸€ä¸ªä»»åŠ¡
				key := address
				jobChan <- serverJob{address: address, server: server, key: key}
			} else {
				for _, port := range server.Ports {
					if strings.TrimSpace(port) == "" {
						continue
					}
					key := fmt.Sprintf("%s:%s", address, port)
					jobChan <- serverJob{address: address, port: port, server: server, key: key}
				}
			}
		}
	}
	close(jobChan)
}

// distributeAddressJobs ä¸ºæ¯ä¸ªæœåŠ¡å™¨åœ°å€åˆ›å»ºä¸€ä¸ªä»»åŠ¡
func distributeAddressJobs(config Config, jobChan chan<- serverJob) {
	// åˆ›å»ºä¸€ä¸ª map æ¥é˜²æ­¢é‡å¤æ·»åŠ ç›¸åŒçš„åœ°å€
	uniqueAddresses := make(map[string]Server)

	for _, server := range config.Servers {
		for _, address := range server.Addresses {
			uniqueAddresses[address] = server
		}
	}

	// ä¸ºæ¯ä¸ªå”¯ä¸€çš„åœ°å€åˆ†å‘ä¸€ä¸ª job
	for addr, srv := range uniqueAddresses {
		jobChan <- serverJob{address: addr, server: srv, key: addr} // key ç›´æ¥ä½¿ç”¨ address
	}
	close(jobChan)
}

// è·å–å¸¦ç¼“å­˜çš„æ£€æŸ¥æ•°æ®
func getCachedCheckData(address string) (*StatusResponse, error) {
	// 1) ä¼˜å…ˆä½¿ç”¨ç¼“å­˜
	if cached, ok := cachedChecks.Load(address); ok {
		if lastTime, ok := lastCheckTime.Load(address); ok {
			if time.Since(lastTime.(time.Time)) < time.Second*time.Duration(checkCacheTTL) {
				return cached.(*StatusResponse), nil
			}
		}
	}

	// 2) æ£€æŸ¥å†·å´çŠ¶æ€
	if val, ok := lastFailure.Load(address); ok {
		if record, ok2 := val.(FailureRecord); ok2 {
			cooldown := time.Duration(config.FailureCooldown) * time.Second
			if time.Since(record.LastFail) < cooldown {
				// å†·å´æœŸå†…ï¼Œä»…é¦–æ¬¡æç¤ºä¸€æ¬¡
				if !record.Notified {
					log.Printf("Error getting check data for %s: recent failure, short-circuited", address)
					record.Notified = true
					lastFailure.Store(address, record)
				}
				return nil, fmt.Errorf("recent failure, short-circuited: %s", address)
			} else {
				// å†·å´è¿‡æœŸ â†’ åˆ é™¤è®°å½•
				lastFailure.Delete(address)
			}
		}
	}

	// 3) å¹¶å‘é™åˆ¶
	select {
	case outboundSem <- struct{}{}:
		defer func() { <-outboundSem }()
	case <-time.After(2 * time.Second):
		return nil, fmt.Errorf("outbound concurrency busy")
	}

	// 4) å¸¦è¶…æ—¶çš„è¯·æ±‚
	ctx, cancel := context.WithTimeout(context.Background(), time.Duration(config.HttpTimeout)*time.Second)
	defer cancel()

	req, err := http.NewRequestWithContext(ctx, "GET", fmt.Sprintf("http://%s:9600/check", address), nil)
	if err != nil {
		lastFailure.Store(address, FailureRecord{LastFail: time.Now(), Notified: false})
		return nil, err
	}

	resp, err := httpClient.Do(req)
	if err != nil {
		lastFailure.Store(address, FailureRecord{LastFail: time.Now(), Notified: false})
		return nil, err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		lastFailure.Store(address, FailureRecord{LastFail: time.Now(), Notified: false})
		return nil, fmt.Errorf("bad status: %d, body: %s", resp.StatusCode, string(body))
	}

	// 5) è§£æå“åº”
	bodyData, err := io.ReadAll(resp.Body)
	if err != nil {
		lastFailure.Store(address, FailureRecord{LastFail: time.Now(), Notified: false})
		return nil, err
	}

	var statusResponse StatusResponse
	if err := json.Unmarshal(bodyData, &statusResponse); err != nil {
		lastFailure.Store(address, FailureRecord{LastFail: time.Now(), Notified: false})
		return nil, err
	}

	// 6) æˆåŠŸ â†’ æ¸…ç†å¤±è´¥è®°å½• & æ›´æ–°ç¼“å­˜
	cachedChecks.Store(address, &statusResponse)
	lastCheckTime.Store(address, time.Now())
	lastFailure.Delete(address)

	return &statusResponse, nil
}

// å¤„ç†PingçŠ¶æ€
// å¤„ç†PingçŠ¶æ€ (æ”¯æŒæœåŠ¡å™¨é‡å¯/å¤±è”/æ¢å¤é€»è¾‘)
func handlePingStatus(address, key string, pingState bool, status *ServerStatus, config Config) {
	if !config.Monitor.ServerReachMonitor {
		return
	}

	// 1. è·å–é…ç½®çš„çª—å£æ—¶é—´ï¼Œé»˜è®¤ 180ç§’
	windowSeconds := config.ServerRestartWindow
	if windowSeconds <= 0 {
		windowSeconds = 600
	}
	window := time.Duration(windowSeconds) * time.Second
	now := time.Now()

	// è·å–PingçŠ¶æ€è¿½è¸ªå™¨ (æ³¨æ„ï¼šPingState æ²¡æœ‰å•ç‹¬çš„é”ï¼Œä¾èµ– statusesMutex æˆ–é»˜è®¤å¹¶å‘å®‰å…¨)
	// å¦‚æœæ‹…å¿ƒå¹¶å‘ï¼Œå¯ä»¥å¤ç”¨ status.PingState ä¸Šçš„å­—æ®µï¼Œä½† ServerStatus æ˜¯é’ˆå¯¹ key ç‹¬ç«‹çš„ï¼Œé€šå¸¸æ˜¯å®‰å…¨çš„ã€‚
	tracker := status.PingState
	if tracker == nil {
		tracker = &StateTracker{}
		status.PingState = tracker
	}

	isReachable := pingState

	if !isReachable {
		// === å½“å‰çŠ¶æ€ï¼šPing ä¸é€š (DOWN) ===

		if tracker.FirstFailureTime.IsZero() {
			// A. åˆšå¤±è”ï¼šè®°å½•æ—¶é—´
			tracker.FirstFailureTime = now
			log.Printf("æœåŠ¡å™¨ %s é€šä¿¡ä¸­æ–­ï¼Œè¿›å…¥è§‚å¯ŸæœŸ (%ds)", address, windowSeconds)
		} else {
			// B. æŒç»­å¤±è”
			timeSinceDown := now.Sub(tracker.FirstFailureTime)

			if timeSinceDown > window && !tracker.AlertSent {
				// è¶…è¿‡çª—å£ï¼Œå‘é€ "å¤±è”å‘Šè­¦"
				data := EmailTemplateData{
					Subject:   "ğŸš¨æœåŠ¡å™¨å¤±è”å‘Šè­¦",
					Server:    address,
					Message:   fmt.Sprintf("æœåŠ¡å™¨é€šä¿¡å¤±è”å·²è¶…è¿‡ %d ç§’ï¼Œå¦‚å½±å“ä¸šåŠ¡è¯·åŠæ—¶å¤„ç†ï¼", windowSeconds),
					Action:    "è¯·å‰å¾€æœºæˆ¿æˆ–è”ç³»è¿ç»´æ£€æŸ¥ç½‘ç»œå’Œä¸»æœºçŠ¶æ€ï¼",
					Timestamp: now.Format("2006-01-02 15:04:05"),
				}
				sendAlert("critical", data)
				tracker.AlertSent = true
				log.Printf("æœåŠ¡å™¨ %s ç¡®è®¤å¤±è”ï¼Œå·²å‘é€å‘Šè­¦", address)
			}
		}

	} else {
		// === å½“å‰çŠ¶æ€ï¼šPing é€šäº† (UP) ===

		if !tracker.FirstFailureTime.IsZero() {
			// ä¹‹å‰æ˜¯ä¸é€šçš„ï¼Œç°åœ¨é€šäº†
			timeSinceDown := now.Sub(tracker.FirstFailureTime)

			if tracker.AlertSent {
				// C. ä¹‹å‰å‘è¿‡å¤±è”å‘Šè­¦ (Confirmed DOWN -> UP) -> ç°åœ¨æ˜¯ "æ¢å¤"
				data := EmailTemplateData{
					Subject:   "âœ…æœåŠ¡å™¨é€šä¿¡æ¢å¤",
					Server:    address,
					Message:   "æœåŠ¡å™¨é€šä¿¡å·²æ¢å¤æ­£å¸¸ï¼Œè¯·æ£€æŸ¥æ‰€æ‰¿è½½ä¸šåŠ¡æ˜¯å¦å·²æ­£å¸¸å¯åŠ¨ï¼",
					Timestamp: now.Format("2006-01-02 15:04:05"),
				}
				sendAlert("recovery", data)
				log.Printf("æœåŠ¡å™¨ %s é€šä¿¡æ¢å¤ï¼Œå·²å‘é€é‚®ä»¶", address)

			} else {
				// D. è¿˜æ²¡å‘è¿‡å‘Šè­¦å°±é€šäº† (Pending DOWN -> UP) -> åˆ¤å®šä¸º "æœåŠ¡å™¨é‡å¯"
				data := EmailTemplateData{
					Subject:   "ğŸ”„æœåŠ¡å™¨é€šä¿¡é—ªæ–­/é‡å¯å‘Šè­¦",
					Server:    address,
					Message:   fmt.Sprintf("æœåŠ¡å™¨ç›‘æµ‹åˆ°é€šä¿¡é—ªæ–­ (é€šä¿¡ä¸­æ–­æ—¶é•¿çº¦ %s)ï¼Œé€šä¿¡å·²è‡ªåŠ¨æ¢å¤ã€‚", timeSinceDown.Round(time.Second)),
					Action:    "æ£€æµ‹åˆ°æœåŠ¡å™¨é€šä¿¡é—ªæ–­æˆ–å¯èƒ½é‡å¯ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿæ—¥å¿—ã€‚",
					Timestamp: now.Format("2006-01-02 15:04:05"),
				}
				sendAlert("critical", data) // é‡å¯é€šå¸¸æ¯”è¾ƒé‡è¦ï¼Œå»ºè®® severe
				log.Printf("æœåŠ¡å™¨ %s ç›‘æµ‹åˆ°é‡å¯ï¼Œå·²å‘é€é‚®ä»¶", address)
			}

			// é‡ç½®çŠ¶æ€
			tracker.FirstFailureTime = time.Time{}
			tracker.AlertSent = false
		}
	}
}

// å¤„ç†ç«¯å£çŠ¶æ€
func handlePortStatus(address, port, key string, portState bool, status *ServerStatus, config Config) {
	status.PortMutex.Lock()
	defer status.PortMutex.Unlock()
	// è·å–é…ç½®çª—å£ï¼Œé»˜è®¤ 60ç§’
	windowSeconds := config.PortRestartWindow
	if windowSeconds <= 0 {
		windowSeconds = 180
	}
	window := time.Duration(windowSeconds) * time.Second
	now := time.Now()
	// è·å–çŠ¶æ€è¿½è¸ªå™¨ (Key ä½¿ç”¨ç«¯å£å·)
	tracker, exists := status.PortStates[port]
	if !exists {
		tracker = &StateTracker{}
		status.PortStates[port] = tracker
	}

	//portAlertSent := atomic.LoadInt32(&status.PortAlertSent) == 1
	if !portState {
		// === ç«¯å£ä¸é€š (DOWN) ===
		if tracker.FirstFailureTime.IsZero() {
			// åˆšå‘ç°ä¸é€šï¼šè®°å½•æ—¶é—´ï¼Œè¿›å…¥è§‚å¯ŸæœŸ
			tracker.FirstFailureTime = now
			log.Printf("æœåŠ¡å™¨ %s ç«¯å£ %s å¼‚å¸¸å¤±è”ï¼Œè¿›å…¥è§‚å¯ŸæœŸ (%ds)", address, port, windowSeconds)
		} else {
			// æŒç»­ä¸é€š
			timeSinceDown := now.Sub(tracker.FirstFailureTime)
			// è¶…è¿‡çª—å£æœŸä¸”æœªå‘Šè­¦ -> å‘é€ä¸¥é‡å‘Šè­¦
			if timeSinceDown > window && !tracker.AlertSent {
				data := EmailTemplateData{
					Subject:   "âš ï¸âš ï¸ç«¯å£å¤±è”å‘Šè­¦",
					Server:    address,
					Message:   fmt.Sprintf("æœåŠ¡å™¨ç«¯å£ %s å¤±è”å·²è¶…è¿‡ %d ç§’ï¼Œè¯·æ£€æŸ¥ç›¸å…³è¿›ç¨‹ï¼", port, windowSeconds),
					Action:    "è¯·ç™»å½•æœåŠ¡å™¨æ£€æŸ¥ç«¯å£ç›‘å¬çŠ¶æ€åŠè¿›ç¨‹æ—¥å¿—ã€‚",
					Timestamp: now.Format("2006-01-02 15:04:05"),
				}
				sendAlert("severe", data) // ä½¿ç”¨ severe çº§åˆ«
				tracker.AlertSent = true
				log.Printf("æœåŠ¡å™¨ %s ç«¯å£ %s ç¡®è®¤å¤±è”ï¼Œå·²å‘é€å‘Šè­¦", address, port)
			}
		}
	} else {
		// === ç«¯å£é€š (UP) ===
		if !tracker.FirstFailureTime.IsZero() {
			timeSinceDown := now.Sub(tracker.FirstFailureTime)

			if tracker.AlertSent {
				// ä¹‹å‰å‘è¿‡å¤±è”å‘Šè­¦ -> å‘é€æ¢å¤é€šçŸ¥
				data := EmailTemplateData{
					Subject:   "âœ…ç«¯å£é€šä¿¡æ¢å¤",
					Server:    address,
					Message:   fmt.Sprintf("æœåŠ¡å™¨ç«¯å£ %s é€šä¿¡å·²æ¢å¤æ­£å¸¸ã€‚", port),
					Timestamp: now.Format("2006-01-02 15:04:05"),
				}
				sendAlert("recovery", data)
				log.Printf("æœåŠ¡å™¨ %s ç«¯å£ %s é€šä¿¡æ¢å¤ï¼Œå‘é€æ¢å¤é‚®ä»¶", address, port)
			} else {
				// æ²¡å‘è¿‡å‘Šè­¦å°±æ¢å¤äº† -> åˆ¤å®šä¸º ç«¯å£é—ªæ–­/è¿›ç¨‹é‡å¯
				data := EmailTemplateData{
					Subject:   "ğŸ”„ç«¯å£é‡å¯/é—ªæ–­å‘Šè­¦",
					Server:    address,
					Message:   fmt.Sprintf("æœåŠ¡å™¨ç«¯å£ %s å‘ç”Ÿé—ªæ–­æˆ–é‡å¯ (ä¸­æ–­æ—¶é•¿çº¦ %s)ã€‚", port, timeSinceDown.Round(time.Second)),
					Action:    "æ£€æµ‹åˆ°ç«¯å£çŸ­æ—¶é—´ä¸å¯ç”¨ï¼Œè¯·å…³æ³¨æœåŠ¡ç¨³å®šæ€§ã€‚",
					Timestamp: now.Format("2006-01-02 15:04:05"),
				}
				// å»ºè®®ä½¿ç”¨ warning çº§åˆ«
				sendAlert("severe", data)
				log.Printf("æœåŠ¡å™¨ %s ç«¯å£ %s æ£€æµ‹åˆ°é—ªæ–­/é‡å¯ï¼Œå‘é€å‘Šè­¦", address, port)
			}

			// é‡ç½®çŠ¶æ€
			tracker.FirstFailureTime = time.Time{}
			tracker.AlertSent = false
		}
	}
}

// å¤„ç†è¿›ç¨‹çŠ¶æ€ (æ”¯æŒé‡å¯/æ¶ˆå¤±/æ¢å¤é€»è¾‘)
func handleProcessStatus(address, key string, processes []ProcessStatus, status *ServerStatus, config Config) {
	status.ProcessMutex.Lock()
	defer status.ProcessMutex.Unlock()

	// 1. è·å–é…ç½®çš„çª—å£æ—¶é—´ï¼Œé»˜è®¤ 60ç§’
	windowSeconds := config.ProcessRestartWindow
	if windowSeconds <= 0 {
		windowSeconds = 180
	}
	window := time.Duration(windowSeconds) * time.Second
	now := time.Now()

	for _, result := range processes {
		procName := result.ProcessName
		isRunning := result.IsRunning

		// è·å–è¯¥è¿›ç¨‹çš„çŠ¶æ€è¿½è¸ªå™¨
		tracker, exists := status.ProcessStates[procName]
		if !exists {
			tracker = &StateTracker{}
			status.ProcessStates[procName] = tracker
		}

		if !isRunning {
			// === å½“å‰çŠ¶æ€ï¼šè¿›ç¨‹ä¸å­˜åœ¨ (DOWN) ===

			if tracker.FirstFailureTime.IsZero() {
				// A. åˆšå‘ç°æŒ‚äº†ï¼šè®°å½•æ—¶é—´ï¼Œæš‚ä¸å‘Šè­¦ (è¿›å…¥ Pending DOWN)
				tracker.FirstFailureTime = now
				log.Printf("æœåŠ¡å™¨ %s è¿›ç¨‹ %s å¼‚å¸¸åœæ­¢ï¼Œè¿›å…¥è§‚å¯ŸæœŸ (%ds)", address, procName, windowSeconds)
			} else {
				// B. å·²ç»æŒ‚äº†ä¸€æ®µæ—¶é—´äº†
				timeSinceDown := now.Sub(tracker.FirstFailureTime)

				// å¦‚æœè¶…è¿‡äº†çª—å£æœŸï¼Œä¸”è¿˜æ²¡å‘è¿‡å‘Šè­¦ -> å‘é€ "è¿›ç¨‹æ¶ˆå¤±" å‘Šè­¦
				if timeSinceDown > window && !tracker.AlertSent {
					data := EmailTemplateData{
						Subject:   "âš ï¸è¿›ç¨‹æ¶ˆå¤±å‘Šè­¦",
						Server:    address,
						Message:   fmt.Sprintf("æœåŠ¡å™¨è¿›ç¨‹ %s å·²åœæ­¢è¶…è¿‡ %d ç§’ï¼Œç¡®è®¤ä¸ºæ•…éšœã€‚", procName, windowSeconds),
						Action:    "è¯·ç™»å½•æœåŠ¡å™¨æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜åœ¨ï¼Œæˆ–è€…æ˜¯å¦æœ‰é‡å¯ç°è±¡ï¼",
						Timestamp: now.Format("2006-01-02 15:04:05"),
					}
					sendAlert("severe", data)
					tracker.AlertSent = true // æ ‡è®°ä¸ºå·²å‘é€ç¡®è®¤æ•…éšœå‘Šè­¦
					log.Printf("æœåŠ¡å™¨ %s è¿›ç¨‹ %s ç¡®è®¤æ¶ˆå¤± (è¶…è¿‡è§‚å¯ŸæœŸ)ï¼Œå·²å‘é€å‘Šè­¦", address, procName)
				}
			}

		} else {
			// === å½“å‰çŠ¶æ€ï¼šè¿›ç¨‹è¿è¡Œä¸­ (UP) ===

			if !tracker.FirstFailureTime.IsZero() {
				// ä¹‹å‰æœ‰æ•…éšœè®°å½•ï¼Œç°åœ¨æ¢å¤äº† -> éœ€è¦åˆ¤æ–­æ˜¯é‡å¯è¿˜æ˜¯æ¢å¤
				timeSinceDown := now.Sub(tracker.FirstFailureTime)

				if tracker.AlertSent {
					// C. ä¹‹å‰å·²ç»å‘è¿‡ "æ¶ˆå¤±å‘Šè­¦" (Confirmed DOWN -> UP)
					// è¿™æ„å‘³ç€æ•…éšœæ—¶é—´ > çª—å£æœŸï¼Œç°åœ¨æ˜¯ "æ¢å¤"
					data := EmailTemplateData{
						Subject:   "âœ…è¿›ç¨‹å·²å¯åŠ¨(æ¢å¤)",
						Server:    address,
						Message:   fmt.Sprintf("æœåŠ¡å™¨è¿›ç¨‹ %s å·²é‡æ–°å¯åŠ¨ï¼", procName),
						Action:    "è¿›ç¨‹å·²æ¢å¤ï¼Œè¯·è§‚å¯Ÿæ˜¯å¦æœ‰å¼‚å¸¸ï¼",
						Timestamp: now.Format("2006-01-02 15:04:05"),
					}
					sendAlert("recovery", data)
					log.Printf("æœåŠ¡å™¨ %s è¿›ç¨‹ %s å·²æ¢å¤ï¼Œå‘é€æ¢å¤é‚®ä»¶", address, procName)

				} else {
					// D. è¿˜æ²¡å‘è¿‡å‘Šè­¦å°±æ¢å¤äº† (Pending DOWN -> UP)
					// è¿™æ„å‘³ç€æ•…éšœæ—¶é—´ < çª—å£æœŸï¼Œåˆ¤å®šä¸º "é‡å¯"
					data := EmailTemplateData{
						Subject:   "âš ï¸ğŸ”„è¿›ç¨‹é‡å¯å‘Šè­¦",
						Server:    address,
						Message:   fmt.Sprintf("æœåŠ¡å™¨è¿›ç¨‹ %s å‘ç”Ÿé‡å¯ (ä¸­æ–­æ—¶é•¿çº¦ %s)ã€‚", procName, timeSinceDown.Round(time.Second)),
						Action:    "æ£€æµ‹åˆ°è¿›ç¨‹åœ¨çŸ­æ—¶é—´å†…é‡å¯ï¼Œè¯·æ£€æŸ¥åº”ç”¨æ—¥å¿—ã€‚",
						Timestamp: now.Format("2006-01-02 15:04:05"),
					}
					// è¿™é‡Œæ ¹æ®éœ€è¦å¯ä»¥é€‰æ‹© warning æˆ– info çº§åˆ«
					sendAlert("warning", data)
					log.Printf("æœåŠ¡å™¨ %s è¿›ç¨‹ %s æ£€æµ‹åˆ°é‡å¯ï¼Œå‘é€å‘Šè­¦", address, procName)
				}

				// é‡ç½®çŠ¶æ€ï¼Œå›åˆ°æ­£å¸¸çŠ¶æ€
				tracker.FirstFailureTime = time.Time{} // é‡ç½®ä¸º Zero
				tracker.AlertSent = false
			}
			// å¦‚æœæœ¬æ¥å°±æ˜¯æ­£å¸¸çš„ (FirstFailureTime IsZero)ï¼Œä»€ä¹ˆéƒ½ä¸ç”¨åš
		}
	}
}

// å¤„ç†èµ„æºçŠ¶æ€
func handleResourceStatus(address, key string, metrics Metrics, server Server, status *ServerStatus, config Config) {
	// åŸå­æ“ä½œç®¡ç†çŠ¶æ€
	cpuAlertSent := atomic.LoadInt32(&status.CpuAlertSent) == 1
	// ä½¿ç”¨äº’æ–¥ä¿æŠ¤èµ„æºç›¸å…³çŠ¶æ€
	status.ResourceMutex.Lock()
	defer status.ResourceMutex.Unlock()

	// é…ç½®å‚æ•°ï¼ˆå¯æ”¹ä¸ºé…ç½®é¡¹ï¼‰
	consecutiveToAlert := config.ConsecutiveToAlert     // è¿ç»­è¶…è¿‡é˜ˆå€¼æ¬¡æ•°æ‰å‘Šè­¦
	consecutiveToRecover := config.ConsecutiveToRecover // è¿ç»­æ­£å¸¸æ¬¡æ•°æ‰æ¢å¤
	emaAlpha := config.ResourceSmooth                   // EMA å¹³æ»‘ç³»æ•°ï¼Œ0<alpha<=1ï¼Œalpha è¶Šå¤§å“åº”è¶Šå¿«ï¼Œè¶Šå°è¶Šå¹³æ»‘

	// è·å–å½“å‰ CPU å€¼ï¼ˆåŸå§‹ï¼‰
	currentCPU := metrics.CPUUsage

	// å¦‚æœ LastCPUEMA == 0 åˆ™è®¤ä¸ºæœªåˆå§‹åŒ–ï¼Œç›´æ¥è®¾ä¸ºå½“å‰å€¼
	if status.LastCPUEMA == 0 {
		status.LastCPUEMA = currentCPU
	} else {
		// æŒ‡æ•°å¹³æ»‘ï¼ˆEMAï¼‰
		status.LastCPUEMA = emaAlpha*currentCPU + (1-emaAlpha)*status.LastCPUEMA
	}

	smoothedCPU := status.LastCPUEMA

	// ä½¿ç”¨å¹³æ»‘å€¼è¿›è¡Œåˆ¤æ–­ï¼ˆé¿å…å•æ¬¡ spikeï¼‰
	cpuThreshold := server.CPUThreshold

	// è¶…é˜ˆå€¼å¤„ç†ï¼ˆå»æŠ–ï¼‰
	if smoothedCPU > cpuThreshold {
		status.CpuHighCount++
		status.CpuNormalCount = 0
		if status.CpuHighCount >= consecutiveToAlert && !cpuAlertSent {
			data := EmailTemplateData{
				Subject:   "âš ï¸CPUä½¿ç”¨ç‡å‘Šè­¦",
				Server:    address,
				Message:   "CPUä½¿ç”¨ç‡è¶…è¿‡é˜ˆå€¼ï¼ˆå¹³æ»‘å€¼ï¼‰",
				Value:     fmt.Sprintf("%.2f%% (smoothed)", smoothedCPU),
				Threshold: fmt.Sprintf("%.2f%%", cpuThreshold),
				Action:    "è¯·æ£€æŸ¥æœåŠ¡å™¨è´Ÿè½½æƒ…å†µï¼Œå¿…è¦æ—¶è¿›è¡Œæ‰©å®¹æˆ–ä¼˜åŒ–ï¼",
				Timestamp: time.Now().Format("2006-01-02 15:04:05"),
			}
			sendAlert("warning", data)
			log.Printf("æœåŠ¡å™¨ %s CPUåˆ©ç”¨ç‡(å¹³æ»‘)=%.2f è¶…è¿‡é˜ˆå€¼ %.2fï¼Œè¯·ç¡®è®¤å‘Šè­¦é‚®ä»¶å·²å‘é€", address, smoothedCPU, cpuThreshold)
			atomic.StoreInt32(&status.CpuAlertSent, 1)
			// é‡ç½®è®¡æ•°é¿å…é‡å¤å‘é€
			status.CpuHighCount = 0
		}
	} else {
		// æ­£å¸¸å€¼è®¡æ•°ï¼ˆç”¨äºæ¢å¤ï¼‰
		status.CpuNormalCount++
		status.CpuHighCount = 0
		if status.CpuNormalCount >= consecutiveToRecover && cpuAlertSent {
			data := EmailTemplateData{
				Subject:   "âœ…CPUä½¿ç”¨ç‡å·²é™ä½",
				Server:    address,
				Message:   "CPUä½¿ç”¨ç‡å·²æ¢å¤æ­£å¸¸ï¼ˆå¹³æ»‘å€¼ï¼‰",
				Value:     fmt.Sprintf("%.2f%% (smoothed)", smoothedCPU),
				Timestamp: time.Now().Format("2006-01-02 15:04:05"),
			}
			sendAlert("recovery", data)
			log.Printf("æœåŠ¡å™¨ %s CPUåˆ©ç”¨ç‡(å¹³æ»‘)=%.2f æ¢å¤ä½äºé˜ˆå€¼ %.2fï¼Œè¯·ç¡®è®¤æ¢å¤é‚®ä»¶å·²å‘é€", address, smoothedCPU, cpuThreshold)
			atomic.StoreInt32(&status.CpuAlertSent, 0)
			status.CpuNormalCount = 0
		}
	}

	memAlertSent := atomic.LoadInt32(&status.MemAlertSent) == 1

	if metrics.MemoryUsage > server.MemoryThreshold && !memAlertSent {
		data := EmailTemplateData{
			Subject:   "âš ï¸å†…å­˜ä½¿ç”¨ç‡å‘Šè­¦",
			Server:    address,
			Message:   "å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡é˜ˆå€¼ï¼",
			Value:     fmt.Sprintf("%.2f%%", metrics.MemoryUsage),
			Threshold: fmt.Sprintf("%.2f%%", server.MemoryThreshold),
			Action:    "è¯·æ£€æŸ¥æœåŠ¡å™¨è¿›ç¨‹å ç”¨å†…å­˜æƒ…å†µï¼Œå¿…è¦æ—¶è¿›ç¨‹å†…å­˜åˆ†é…ä¼˜åŒ–æˆ–æ‰©å®¹ï¼",
			Timestamp: time.Now().Format("2006-01-02 15:04:05"),
		}
		sendAlert("warning", data)
		log.Printf("æœåŠ¡å™¨ %s å†…å­˜åˆ©ç”¨ç‡å·²è¾¾åˆ° %.2f%% è¶…è¿‡é˜ˆå€¼ï¼Œè¯·ç¡®è®¤å‘Šè­¦é‚®ä»¶å·²å‘é€", address, metrics.MemoryUsage)
		atomic.StoreInt32(&status.MemAlertSent, 1)
	} else if metrics.MemoryUsage < server.MemoryThreshold && memAlertSent {
		data := EmailTemplateData{
			Subject:   "âœ…å†…å­˜ä½¿ç”¨ç‡å·²é™ä½",
			Server:    address,
			Message:   "æœåŠ¡å™¨å†…å­˜ä½¿ç”¨ç‡å·²é™ä½ï¼Œæ¢å¤æ­£å¸¸ï¼",
			Value:     fmt.Sprintf("%.2f%%", metrics.MemoryUsage),
			Timestamp: time.Now().Format("2006-01-02 15:04:05"),
		}
		sendAlert("recovery", data)
		log.Printf("æœåŠ¡å™¨ %s å†…å­˜åˆ©ç”¨ç‡å·²é™åˆ° %.2f%% ï¼Œè¯·ç¡®è®¤æ¢å¤é‚®ä»¶å·²å‘é€", address, metrics.MemoryUsage)
		atomic.StoreInt32(&status.MemAlertSent, 0)
	}

	// ç£ç›˜çŠ¶æ€å¤„ç†
	diskMutex := &status.DiskMutex
	diskMap := &status.DiskAlertSent

	diskMutex.Lock()

	for mountpoint, usage := range metrics.DiskUsage {
		if isExcludedMountPoint(mountpoint, server.ExcludeMountPoints) {
			continue
		}

		alertSent, exists := (*diskMap)[mountpoint]
		if !exists {
			(*diskMap)[mountpoint] = 0
			alertSent = 0
		}

		if usage > server.DiskThreshold && alertSent == 0 {
			data := EmailTemplateData{
				Subject:   "âš ï¸ç£ç›˜ä½¿ç”¨ç‡å‘Šè­¦",
				Server:    address,
				Message:   "ç£ç›˜åˆ©ç”¨ç‡è¶…è¿‡é˜ˆå€¼ï¼",
				Value:     fmt.Sprintf("%.2f%% æŒ‚è½½ç‚¹ï¼š%s", usage, mountpoint),
				Threshold: fmt.Sprintf("%.2f%%", server.DiskThreshold),
				Action:    "è¯·æ£€æŸ¥æœåŠ¡å™¨ç£ç›˜åˆ†åŒºä½¿ç”¨æƒ…å†µï¼Œå¿…è¦æ—¶è¿›è¡Œæ¸…ç†æˆ–æ‰©å®¹ï¼",
				Timestamp: time.Now().Format("2006-01-02 15:04:05"),
			}
			sendAlert("critical", data)
			log.Printf("æœåŠ¡å™¨ %s æŒ‚è½½ç‚¹ %s åˆ©ç”¨ç‡å·²è¾¾åˆ° %.2f%% è¶…è¿‡é˜ˆå€¼ï¼Œè¯·ç¡®è®¤å‘Šè­¦é‚®ä»¶å·²å‘é€",
				address, mountpoint, usage)
			(*diskMap)[mountpoint] = 1
		} else if usage < server.DiskThreshold && alertSent == 1 {
			data := EmailTemplateData{
				Subject:   "âœ…ç£ç›˜åˆ©ç”¨ç‡å·²é™ä½",
				Server:    address,
				Message:   "æœåŠ¡å™¨ç£ç›˜åˆ©ç”¨ç‡å·²é™ä½ï¼Œæ¢å¤æ­£å¸¸ï¼",
				Value:     fmt.Sprintf("%.2f%% æŒ‚è½½ç‚¹ï¼š%s", usage, mountpoint),
				Timestamp: time.Now().Format("2006-01-02 15:04:05"),
			}
			sendAlert("recovery", data)
			log.Printf("æœåŠ¡å™¨ %s æŒ‚è½½ç‚¹ %s åˆ©ç”¨ç‡å·²é™åˆ° %.2f%% ï¼Œè¯·ç¡®è®¤æ¢å¤é‚®ä»¶å·²å‘é€",
				address, mountpoint, usage)
			(*diskMap)[mountpoint] = 0
		}
	}
	diskMutex.Unlock()
}

// å¤„ç†ç›®å½•çŠ¶æ€
func handleDirectoryStatus(address, key string, dirs []DirectoryStatus, status *ServerStatus, config Config, now time.Time) {
	dirMutex := &status.DirMutex
	dirMap := &status.DirAlertSent
	fileMap := &status.FileAlertSent

	dirMutex.Lock()
	defer dirMutex.Unlock()

	for _, result := range dirs {
		baseDir := result.BaseDir
		folderExists := result.DirectoryExist
		fileActuallyExists := result.XdrFileExist // âœ… ä½¿ç”¨æ¥å£è¿”å›çš„æ–‡ä»¶å­˜åœ¨çŠ¶æ€

		// åˆå§‹åŒ–ç›®å½•å‘Šè­¦çŠ¶æ€
		dirAlertSent, ok1 := (*dirMap)[baseDir]
		if !ok1 {
			(*dirMap)[baseDir] = 0
			dirAlertSent = 0
		}

		// åˆå§‹åŒ–æ–‡ä»¶å‘Šè­¦çŠ¶æ€
		fileAlertSent, ok2 := (*fileMap)[baseDir]
		if !ok2 {
			(*fileMap)[baseDir] = 0
			fileAlertSent = 0
		}

		// 1. ç›®å½•/æ–‡ä»¶ç¼ºå¤±å‘Šè­¦
		if !folderExists && !fileActuallyExists && dirAlertSent == 0 {
			data := EmailTemplateData{
				Subject:   "âš ï¸âš ï¸ç›®å½•/æ–‡ä»¶ç¼ºå¤±å‘Šè­¦",
				Server:    address,
				Message:   fmt.Sprintf("æœåŠ¡å™¨ç›®å½• %s ä¸å­˜åœ¨æŒ‡å®šç›®å½•æˆ–æ–‡ä»¶ï¼", baseDir),
				Action:    "è¯·æ£€æŸ¥æœåŠ¡å™¨è¾“å‡ºæ–‡ä»¶è¿›ç¨‹æ˜¯å¦æ­£å¸¸è¿è¡Œï¼",
				Timestamp: now.Format("2006-01-02 15:04:05"),
			}
			sendAlert("warning", data)
			log.Printf("æœåŠ¡å™¨ %s ç›®å½• %s ä¸å­˜åœ¨æŒ‡å®šç›®å½•/æ–‡ä»¶ï¼Œè¯·ç¡®è®¤å‘Šè­¦é‚®ä»¶å·²å‘é€",
				address, baseDir)
			(*dirMap)[baseDir] = 1
		} else if (folderExists || fileActuallyExists) && dirAlertSent == 1 {
			data := EmailTemplateData{
				Subject:   "âœ…ç›®å½•/æ–‡ä»¶å·²æ¢å¤",
				Server:    address,
				Message:   fmt.Sprintf("æœåŠ¡å™¨ç›®å½• %s æ–‡ä»¶/ç›®å½•å·²æ¢å¤ï¼", baseDir),
				Timestamp: now.Format("2006-01-02 15:04:05"),
			}
			sendAlert("recovery", data)
			log.Printf("æœåŠ¡å™¨ %s ç›®å½• %s ç›®å½•/æ–‡ä»¶å·²å­˜åœ¨ï¼Œè¯·ç¡®è®¤æ¢å¤é‚®ä»¶å·²å‘é€",
				address, baseDir)
			(*dirMap)[baseDir] = 0
		}

		// 2. æ–‡ä»¶ç¼ºå¤±å‘Šè­¦ï¼ˆç›®å½•å­˜åœ¨ä½†æ–‡ä»¶ç¼ºå¤±ï¼‰
		if folderExists {
			if !fileActuallyExists && fileAlertSent == 0 {
				data := EmailTemplateData{
					Subject:   "âš ï¸âš ï¸æ–‡ä»¶ç¼ºå¤±å‘Šè­¦",
					Server:    address,
					Message:   fmt.Sprintf("æœåŠ¡å™¨ç›®å½• %s ä¸å­˜åœ¨æŒ‡å®šæ–‡ä»¶ï¼", baseDir),
					Action:    "è¯·æ£€æŸ¥æœåŠ¡å™¨è¾“å‡ºæˆ–è½¬ç§»æ–‡ä»¶è¿›ç¨‹æ˜¯å¦æ­£å¸¸è¿è¡Œï¼",
					Timestamp: now.Format("2006-01-02 15:04:05"),
				}
				sendAlert("warning", data)
				log.Printf("æœåŠ¡å™¨ %s ç›®å½• %s ä¸å­˜åœ¨æŒ‡å®šæ–‡ä»¶ï¼Œè¯·ç¡®è®¤å‘Šè­¦é‚®ä»¶å·²å‘é€",
					address, baseDir)
				(*fileMap)[baseDir] = 1
			} else if fileActuallyExists && fileAlertSent == 1 {
				data := EmailTemplateData{
					Subject:   "âœ…ç›®å½•æ–‡ä»¶å·²æ¢å¤",
					Server:    address,
					Message:   fmt.Sprintf("æœåŠ¡å™¨ç›®å½• %s å†…æ–‡ä»¶å·²æ¢å¤ï¼", baseDir),
					Timestamp: now.Format("2006-01-02 15:04:05"),
				}
				sendAlert("recovery", data)
				log.Printf("æœåŠ¡å™¨ %s ç›®å½• %s æ–‡ä»¶å·²å­˜åœ¨ï¼Œè¯·ç¡®è®¤æ¢å¤é‚®ä»¶å·²å‘é€",
					address, baseDir)
				(*fileMap)[baseDir] = 0
			}
		}
	}
}

// å¤„ç†ç›®æ ‡ç«¯å£çŠ¶æ€
func handleTargetPortStatus(address, key string, ports []PortStatus, status *ServerStatus, config Config) {
	status.TargetPortMutex.Lock()
	defer status.TargetPortMutex.Unlock()

	windowSeconds := config.PortRestartWindow
	if windowSeconds <= 0 {
		windowSeconds = 180
	}
	window := time.Duration(windowSeconds) * time.Second
	now := time.Now()

	for _, result := range ports {
		hostName := result.Host
		targetPort := result.Port
		portState := result.Status

		// è·å–è¿½è¸ªå™¨ (Key ä½¿ç”¨ç›®æ ‡ä¸»æœºå)
		tracker, exists := status.TargetPortStates[hostName]
		if !exists {
			tracker = &StateTracker{}
			status.TargetPortStates[hostName] = tracker
		}

		if !portState {
			// === ç›®æ ‡ç«¯å£ä¸é€š ===
			if tracker.FirstFailureTime.IsZero() {
				tracker.FirstFailureTime = now
				log.Printf("æœåŠ¡å™¨ %s è®¿é—®ç›®æ ‡ %s:%d å¤±è´¥ï¼Œè¿›å…¥è§‚å¯ŸæœŸ", address, hostName, targetPort)
			} else {
				timeSinceDown := now.Sub(tracker.FirstFailureTime)
				if timeSinceDown > window && !tracker.AlertSent {
					data := EmailTemplateData{
						Subject:   "âš ï¸ç›®æ ‡æœåŠ¡å™¨ç«¯å£å¤±è”å‘Šè­¦",
						Server:    address,
						Message:   fmt.Sprintf("ä»æœåŠ¡å™¨ %s åˆ°ç›®æ ‡ %s:%d é€šä¿¡å¤±è”è¶…è¿‡ %d ç§’ï¼", address, hostName, targetPort, windowSeconds),
						Action:    "è¯·æ£€æŸ¥ç½‘ç»œé“¾è·¯æˆ–ç›®æ ‡æœåŠ¡å™¨çŠ¶æ€ã€‚",
						Timestamp: now.Format("2006-01-02 15:04:05"),
					}
					sendAlert("severe", data)
					tracker.AlertSent = true
					log.Printf("ç›®æ ‡ %s:%d ç¡®è®¤å¤±è”ï¼Œå‘é€å‘Šè­¦", hostName, targetPort)
				}
			}
		} else {
			// === ç›®æ ‡ç«¯å£æ¢å¤ ===
			if !tracker.FirstFailureTime.IsZero() {
				timeSinceDown := now.Sub(tracker.FirstFailureTime)
				if tracker.AlertSent {
					data := EmailTemplateData{
						Subject:   "âœ…ç›®æ ‡æœåŠ¡å™¨ç«¯å£é€šä¿¡æ¢å¤",
						Server:    address,
						Message:   fmt.Sprintf("åˆ°ç›®æ ‡ %s:%d çš„é€šä¿¡å·²æ¢å¤ã€‚", hostName, targetPort),
						Timestamp: now.Format("2006-01-02 15:04:05"),
					}
					sendAlert("recovery", data)
				} else {
					data := EmailTemplateData{
						Subject:   "ğŸ”„ç›®æ ‡ç«¯å£é—ªæ–­å‘Šè­¦",
						Server:    address,
						Message:   fmt.Sprintf("åˆ°ç›®æ ‡ %s:%d å‘ç”Ÿé€šä¿¡é—ªæ–­ (æ—¶é•¿çº¦ %s)ã€‚", hostName, targetPort, timeSinceDown.Round(time.Second)),
						Timestamp: now.Format("2006-01-02 15:04:05"),
					}
					sendAlert("warning", data)
				}
				tracker.FirstFailureTime = time.Time{}
				tracker.AlertSent = false
			}
		}
	}
}
